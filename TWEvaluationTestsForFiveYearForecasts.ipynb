{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Evaluation Tests for Five-Year Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo provides step-by-step instructions on how to invoke statistical **T** (the classical paired t-test) and **W** (the Wilcoxon signed-rank test) evaluation tests for two five-year RELM forecasts. It also explains which data products and images are generated by the evaluation tests, and allows user to view results. This tutorial uses *EvaluationTest.py* CSEP Python module in standalone mode to invoke the tests. Python code, which is a simplified implementation of standalone functionality of the *EvaluationTest.py* module, is also provided in case users want to integrate this CSEP functionality within their custom Python routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We use command-line options to provide *EvaluationTest.py* module with necessary information about forecasts and observations that are used for the evaluation.\n",
    " \n",
    "   Comparable forecasts files should be placed in the same directory which represents *forecast group*. Forecast group within CSEP is defined as a collection of comparable forecasts for the same testing region with the same target earthquakes. \n",
    "   This test case uses two RELM five-year forecasts which are stored in *RELMEvaluation/forecasts* directory: \n",
    "   * *helmstetter_et_al.hkj.dat*\n",
    "   * *wiemer_schorlemmer.alm.dat*\n",
    "\n",
    "Observation catalog *catalog.dat* with two events is placed in *RELMEvaluation/observations* directory. Observed events should be stored in ASCII [ZMAP](https://northridge.usc.edu/trac/csep/wiki/catalogZMAPformat) format file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command-line options should be provided to the *EvaluationTest.py* module to invoke evalation tests.\n",
    "\n",
    "* *--forecasts=RELMEvaluation/forecasts* - Directory where *helmstetter_et_al.hkj.dat* and *wiemer_schorlemmer.alm.dat* forecasts files in ASCII [CSEPForecast](https://northridge.usc.edu/trac/csep/wiki/ForecastFormat) format are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls RELMEvaluation/forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *--catalog=RELMEvaluation/observations/catalog.dat* - Path to the observation catalog file in ASCII [ZMAP](https://northridge.usc.edu/trac/csep/wiki/catalogZMAPformat) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls RELMEvaluation/observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We use observation catalog which consists of two events and confirms to the ASCII [ZMAP](https://northridge.usc.edu/trac/csep/wiki/catalogZMAPformat) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat RELMEvaluation/observations/catalog.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Forecast's 5-year testing period is defined by start date of 2006/01/01 inclusively and end date of 2011/01/01 exclusively. Test date for evaluation is set to 2006/09/01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *--year=2006* - Year of the test date\n",
    "* *--month=9* - Month of the test date\n",
    "* *--day=1* - Day of the test date\n",
    "* *--startDate=2006-01-01* - Start date of the forecast's testing period\n",
    "* *--endDate=2011-01-01* - End date (exclusively) of the forecast's testing period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The following options provide information about evaluation tests to invoke:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *--tests='T W'* - Space-separated list of evaluation tests to invoke\n",
    "* *--testDir=RELMEvaluation/TWScriptResults* - Directory to store results to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python3 $CENTERCODE/src/generic/EvaluationTest.py --year=2006 --month=9 --day=1 --startDate=2006-01-01 --endDate=2011-01-01 --catalog=RELMEvaluation/observations/catalog.dat --forecasts=RELMEvaluation/forecasts --tests='T W' --testDir=RELMEvaluation/TWScriptResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This section examines data products that **T** and **W** evaluation tests generated by running above **python3** command.\n",
    "   Please note that each data product, as generated by the CSEP, has corresponding metadata file with identical filename with an additional *.meta* extention. Metadata file captures information on how each data product has been generated and is used for reproducibility of the results only. You can ignore all generated *.meta files for now.\n",
    "   \n",
    "   For example, metadata file for the T-Test result file has the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test.xml.*[1-9].meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast Scale Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Forecast scale factor, that corresponds to the test date of 2006/09/01 within testing period, is captured within *TWEvaluation/ScriptResults/ForecastScaleFactor.dat* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat RELMEvaluation/TWScriptResults/ForecastScaleFactor.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test Results Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result file with **scec.csep.StatisticalTest.sTest_T-Test.xml.** prefix respresents T-test evaluation results for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test.xml.*[1-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Information gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **InformationGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, shutil\n",
    "from IPython.core.display import SVG\n",
    "\n",
    "# Locate T-test information gain plot file for Helmstetter forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_helmstetter_et_al.hkj_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for Wiemer/Schorlemmer forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_wiemer_schorlemmer.alm_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Probability gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **ProbabilityGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test probability gain plot file for Helmstetter forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_helmstetter_et_al.hkj_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for Wiemer/Schorlemmer forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_wiemer_schorlemmer.alm_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W-Test ResultsFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result file with **scec.csep.StatisticalTest.sTest_W-Test.xml.** prefix respresents W-test evaluation results for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test.xml.*[1-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Information gain plot, that corresponds to the W-test evaluation results, is stored in SVG format image file with **InformationGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for Helmstetter forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_helmstetter_et_al.hkj_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for Wiemer/Schorlemmer forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_wiemer_schorlemmer.alm_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Probability gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **ProbabilityGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test probability gain plot file for Helmstetter forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_helmstetter_et_al.hkj_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for Wiemer/Schorlemmer forecast\n",
    "image_file = glob.glob('RELMEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_wiemer_schorlemmer.alm_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Your Forecast to the Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   To add your own forecast to the test case, just place your forecast file in ASCII [CSEPForecast](https://northridge.usc.edu/trac/csep/wiki/ForecastFormat) format under *RELMEvaluation/forecasts* directory, and re-run the test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code to Run Evaluation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Detailed Python code below provides (simplified) behind the scenes details of what provided above **python3** command does when *EvaluationTest.py* module is invoked in standalone mode.\n",
    "\n",
    "   Please note that we use different *RELMEvaluation/PythonResults* directory to store results data to when invoking the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Import CSEP modules\n",
    "import CSEPUtils\n",
    "from ForecastGroup import ForecastGroup\n",
    "from EvaluationTest import EvaluationTest\n",
    "from PostProcess import PostProcess\n",
    "from TStatisticalTest import TStatisticalTest\n",
    "from WStatisticalTest import WStatisticalTest\n",
    "\n",
    "# Path to the observation catalog\n",
    "catalog_file = 'RELMEvaluation/observations/catalog.dat'\n",
    "# Path to the forecast group directory\n",
    "forecast_dir = 'RELMEvaluation/forecasts'\n",
    "# Path to the evaluation test results (please note it's different from above 'TWEvaluation/results')\n",
    "results_dir = 'RELMEvaluation/TWPythonResults'\n",
    "test_list = 'T W'\n",
    "\n",
    "# Start date for the testing period\n",
    "start_date = datetime.datetime(2006, 1, 1)\n",
    "\n",
    "# End date for the testing period\n",
    "end_date = datetime.datetime(2011, 1, 1)\n",
    "\n",
    "# Test date for evaluation\n",
    "test_date = datetime.datetime(2006, 9, 1)\n",
    "\n",
    "forecast_duration = CSEPUtils.decimalYear(end_date) - \\\n",
    "                             CSEPUtils.decimalYear(start_date)\n",
    "\n",
    "# Create PostProcess object (catalog filtering thresholds) \n",
    "# and pass it to the ForecastGroup to evaluate\n",
    "min_magnitude = 4.95\n",
    "max_depth = 30.0\n",
    "catalog_files = PostProcess.Files(None,\n",
    "                                  None,\n",
    "                                  catalog_file)\n",
    " \n",
    "post_process = PostProcess(min_magnitude,\n",
    "                           max_depth,\n",
    "                           forecast_duration,\n",
    "                           catalog_files)\n",
    "\n",
    "post_process.startDate(start_date)\n",
    "post_process.endDate(end_date)\n",
    "\n",
    "# Instantiate forecast group for the tests\n",
    "forecast_group = ForecastGroup(forecast_dir,\n",
    "                               post_process,\n",
    "                               test_list)\n",
    "\n",
    "# Run evaluation tests        \n",
    "for each_set in forecast_group.tests:\n",
    "    for each_test in each_set:\n",
    "        # Use the same directory for catalog data and test results: options.test_dir\n",
    "        print('Running %s evaluation test' %each_test.Type)\n",
    "        each_test.run(test_date,\n",
    "                      '.',\n",
    "                      results_dir)\n",
    "         \n",
    "        # Update cumulative summaries if any\n",
    "        each_test.resultData()\n",
    "print('Done with %s evaluation tests for %s group.' %(test_list, forecast_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*RELMEvaluation/TWPythonResults* directory contains the same results as previously examined results generated by the **python3** commmand, just with different filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls RELMEvaluation/TWPythonResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
