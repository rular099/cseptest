{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Evaluation Tests for One-Day Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo provides step-by-step instructions on how to invoke statistical **T** (the classical paired t-test) and **W** (the Wilcoxon signed-rank test) evaluation tests for three one-day California forecasts models over 10 day time period that includes Napa event of August, 24, 2014. It also explains which data products and images are generated by the evaluation tests, and allows user to view results. This tutorial uses *EvaluationTest.py* CSEP Python module in standalone mode to invoke the tests. Python code, which is a simplified implementation of standalone functionality of the *EvaluationTest.py* module, is also provided in case users want to integrate this CSEP functionality within their custom Python routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Forecast group within CSEP is defined as a collection of comparable forecasts for the same testing region with the same target earthquakes. Comparable one-day forecasts files for our test case are stored in *OneDayEvaluation/forecasts* directory, where *OneDayEvaluation* directory represents the group.\n",
    "   \n",
    "   Daily forecasts are organized (''archived'') within CSEP by year and month of the start date of each forecast testing period. Forecast group's directory contains *archive* subdirectory where all previously generated daily forecasts are stored in *archive/YYYY-M[M]* sub-directories. It allows CSEP testing framework to reuse already generated forecasts for any evaluation which requires existence of all daily forecasts prior and including the day of evaluation. For example, statistical evaluation of daily forecasts over the time period of 2014/08/20 - 2014/08/31 requires existence of daily forecasts for each day of that testing period. Archived forecasts files for our test case are stored in *OneDayEvaluaton/forecasts/archive/2014_8* directory.\n",
    "\n",
    "   Please note that *OneDayEvaluaton/forecasts/archive/2014_8* sub-directory represents start date of all forecasts that are involved into this test case evaluation. If testing period would span over 3 months of data (for example, 2014/7/15 through 2014/9/15) then *archive* directory should have sub-directory per each month of existing forecast data (*2014_7*, *2014_8*, *2014_9*). Each of these subdirectories would store forecasts with corresponding start date.\n",
    "\n",
    "   This test case uses three one-day forecasts models for which forecasts files are stored in *OneDayEvaluation/forecasts/archive/2014_8* directory: \n",
    "   * *ETASV1.1*\n",
    "   * *KJSSOneDayCalifornia*\n",
    "   * *STEPJAVA*\n",
    "   \n",
    "   Forecasts files for evaluation test day of 2014/08/31, such as *ETASV1.1_8_31_2014-fromXML.dat*, *STEPJAVA_8_31_2014-fromXML.dat* and *KJSSOneDayCalifornia_8_31_2014-fromXML.dat*, should be stored in *OneDayEvaluation/forecasts* directory. CSEP examines *OneDayEvaluation/forecasts* directory to learn which forecasts models participate in the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls OneDayEvaluation/forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls OneDayEvaluation/forecasts/archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls OneDayEvaluation/forecasts/archive/2014_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  There are two catalog files in the *observations* directory. *catalog.nodecl.dat* is a daily observation catalog, while *cumulative.catalog.nodecl.dat* file represents all observed events since beginning of the testing period, which is set to 2014/08/20 for this test case. T and W evaluation tests use only cumulative observation catalog since evaluation is performed over cumulative testing period of the model's existence within CSEP. Cumulative catalog for this test case consists of two events and confirms to the ASCII [ZMAP](https://northridge.usc.edu/trac/csep/wiki/catalogZMAPformat) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls OneDayEvaluation/observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/observations/cumulative.catalog.nodecl.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Group Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test case relies on forecast group's configuration file *OneDayEvaluation/forecast.init.xml*. CSEP automatically detects any *forecast.init.xml* configuration files that exist for forecasts groups and \"learns\" necessary information about the group's models and evaluations tests for the group from that file. *forecast.init.xml* file is  XML format, with an example for our test case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/forecast.init.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML format elements of such configuration file store necessary information about forecast group and specify which models construct the group as well as evalution tests that are being applied to the forecasts. Configuration file for our test case's group contains the following elements:\n",
    "\n",
    "   * forecastDir - directory to store forecasts files in.\n",
    "   * catalogDir - directory to store observation catalog files in.\n",
    "   * postProcessing - keyword which identifies catalog filtering Python module within CSEP for specific forecast group type. It's set to 'OneDayModel' for our test case, and is specific in how observation catalog is being constructed for evaluation of one-day forecasts.\n",
    "   * entryDate - entry date of participating forecasts models into testing center. This date determines start date for cumulative catalog which is used by evaluation methods of the models.\n",
    "   * models - Space separated list of forecasts models for the group. This list is not being used if forecasts files are not being generated by the test case (like this one).\n",
    "   * evaluationTests - Space separated list of evaluation tests to invoke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use *EvaluationTest.py* Python module in standalone mode to invoke our test case, we also use command-line options to provide *EvaluationTest.py* module with necessary information about forecasts and observations that are being evaluated.\n",
    "\n",
    "The following command-line options should be provided to the *EvaluationTest.py* module to invoke evalation tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Testing period is defined by start date of 2014/08/20 and test date of 2014/08/31 inclusively. Test date for evaluation is set to 2014/08/31."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *--year=2014* - Year of the test date\n",
    "* *--month=8* - Month of the test date\n",
    "* *--day=31* - Day of the test date\n",
    "* *--forecasts=OneDayEvaluation* - Directory that represents forecast group for evaluation\n",
    "* *--testDir=OneDayEvaluation/TWScriptResults* - Directory to store results to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python3 $CENTERCODE/src/generic/EvaluationTest.py --year=2014 --month=8 --day=31 --forecasts=OneDayEvaluation --testDir=OneDayEvaluation/TWScriptResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This section examines data products that **T** and **W** evaluation tests generated by running above **python3** command.\n",
    "   Please note that each data product, as generated by the CSEP, has corresponding metadata file with identical filename with an additional *.meta* extention. Metadata file captures information on how each data product has been generated and is used for reproducibility of the results only. You can ignore all generated *.meta files for now.\n",
    "   \n",
    "   For example, metadata file for the T-Test result file has the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test.xml.*[1-9].meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast Scale Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Forecast scale factor, that corresponds to the test date of 2006/09/01 within testing period, is captured within *OneDayEvaluation/TWScriptResults/ForecastScaleFactor.dat* file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/TWScriptResults/ForecastScaleFactor.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test Results Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result file with **scec.csep.StatisticalTest.sTest_T-Test.xml.** prefix respresents T-test evaluation results for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test.xml.*[1-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Information gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **InformationGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, shutil\n",
    "from IPython.core.display import SVG\n",
    "\n",
    "# Locate T-test information gain plot file for ETAS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_ETASV1.1_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for STEPJava forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_STEPJAVA_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for KJSS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_KJSSOneDayCalifornia_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Probability gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **ProbabilityGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test probability gain plot file for ETAS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_ETASV1.1_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for STEPJava forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_STEPJAVA_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate T-test information gain plot file for KJSS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_T-Test_KJSSOneDayCalifornia_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W-Test ResultsFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result file with **scec.csep.StatisticalTest.sTest_W-Test.xml.** prefix respresents W-test evaluation results for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test.xml.*[1-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Information gain plot, that corresponds to the W-test evaluation results, is stored in SVG format image file with **InformationGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for ETAS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_ETASV1.1_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for STEPJava forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_STEPJAVA_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for KJSS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_KJSSOneDayCalifornia_8_31_2014_InformationGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Probability gain plot, that corresponds to the T-test evaluation results, is stored in SVG format image file with **ProbabilityGain** keyword per each model. Model name appears as part of the SVG image file and as title of the plot, and considered to be a reference model for the results in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test probability gain plot file for ETAS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_ETASV1.1_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for STEPJava forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_STEPJAVA_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate W-test information gain plot file for KJSS forecast\n",
    "image_file = glob.glob('OneDayEvaluation/TWScriptResults/scec.csep.StatisticalTest.sTest_W-Test_KJSSOneDayCalifornia_8_31_2014_ProbabilityGain.svg.*[0-9]')[0]\n",
    "print(image_file)\n",
    "SVG(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Your Forecast to the Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   To add your own forecast to the test case, please place your daily forecast file for the test date of 2014/08/31 in ASCII [CSEPForecast](https://northridge.usc.edu/trac/csep/wiki/ForecastFormat) format under *OneDayEvaluation/forecasts* directory. Forecast file name should follow the same naming convention as existing forecasts: ModelName_M_D_YYYY.dat. Other daily forecasts files that correspond to the whole testing period should be placed under *OneDayEvaluation/forecasts/archive/2014_8* directory. Once forecasts files have been added to the forecast group's directory structure, you can just re-run the test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code to Run Evaluation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Detailed Python code below provides (simplified) behind the scenes details of what provided above **python3** command does when *EvaluationTest.py* module is invoked in standalone mode.\n",
    "\n",
    "   Please note that we use different *OneDayEvaluation/PythonResults* directory to store results data to when invoking the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Import CSEP modules\n",
    "import CSEPUtils\n",
    "from ForecastGroup import ForecastGroup\n",
    "from EvaluationTest import EvaluationTest\n",
    "from PostProcess import PostProcess\n",
    "from TStatisticalTest import TStatisticalTest\n",
    "from WStatisticalTest import WStatisticalTest\n",
    "\n",
    "# Path to the forecast group directory\n",
    "forecast_dir = 'OneDayEvaluation'\n",
    "# Path to the evaluation test results (please note it's different from above 'OneDayEvaluation/TWScriptResults')\n",
    "results_dir = 'OneDayEvaluation/PythonResults'\n",
    "\n",
    "# Test date for evaluation\n",
    "test_date = datetime.datetime(2014, 8, 31)\n",
    "\n",
    "# Instantiate forecast group for the tests\n",
    "forecast_group = ForecastGroup(forecast_dir)\n",
    "\n",
    "# Observation catalog directory as provided in OneDayEvaluation/forecast.init.xml file\n",
    "catalog_dir = forecast_group.catalogDir()\n",
    "\n",
    "# Run evaluation tests        \n",
    "for each_set in forecast_group.tests:\n",
    "    for each_test in each_set:\n",
    "        # Use the same directory for catalog data and test results: options.test_dir\n",
    "        print('Running %s evaluation test' %each_test.Type)\n",
    "        each_test.run(test_date,\n",
    "                      catalog_dir,\n",
    "                      results_dir)\n",
    "         \n",
    "        # Update cumulative summaries if any\n",
    "        each_test.resultData()\n",
    "       \n",
    "del forecast_group\n",
    "forecast_group = None\n",
    "\n",
    "print('Done with evaluation tests for %s group.' %forecast_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OneDayEvaluation/PythonResults* directory contains the same results as previously examined results generated by the **python3** commmand, just with different filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls OneDayEvaluation/PythonResults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
